\begin{frame}{Part A}
Non-Uniform Sampling Algorithms
\end{frame}

\begin{frame}{Problem}
\[
\min_{x\in\R^n} f(\wv)
\]
\begin{block}{Remark}
$f$ is a $\lambda$-strongly convex function.
\end{block}
\end{frame}

\begin{frame}{NonUnifSGD}
\begin{algorithm}[H]
    \label{alg:SGD}
    \caption{Non-Uniform Stochastic Gradient Discent}
    \SetKwInput{Init}{Initialize}
    \SetKwFor{Forloop}{for}{}{end}
    \SetAlgoLined
    \KwIn{$\lambda > 0$, $p_i = \frac{\|\xv_i\|}{\sum_{j=1}^n \|\xv_j\|}, \forall i\in \{1,\ldots,n\}.$
    }
    \KwData{$\{(\xv_i,y_i)\}_{i=1}^n$.}
    \Init{
        $\wv^{1}= \textbf{0}$.
    }
    \Forloop{ $t = 1,2, \dots ,T$}{
        Sample $i_t$ from $\{1,\ldots,n\}$ based on $\p$; \\
        Set stepsize $\eta_t \leftarrow \frac{1}{\lambda t}$; \\
        Set $\chiv_{i_t}^t(\wv^{t}) \leftarrow \ell'(\langle \wv^{t}, \xv_{i_t}\rangle, y_{i_t}) \xv_{i_t}+ \lambda \nabla r(\wv^t)$;\\
        Set $\gv_{i_t}^t \leftarrow \frac{\chiv_{i_t}^t(\wv^{t})}{np_{i_t}}$;\\
        Set $\wv^{t+1} \leftarrow \wv^{t}-\eta_t\gv_{i_t}^t$;
    }
    \KwOut{$\wv^{T+1}$}
\end{algorithm}
\end{frame}

\begin{frame}{Key inequality}
\begin{align*}\label{neq:fworigin}
    & \E[f(\wv^{t})]-f(\wv^*)   \le \\
    & \frac{\eta_t}{2}\E[\|\gv_{i_t}^t\|^2] +\frac{1-\lambda \eta_t}{2\eta_t} \E[\|\wv^{t}-\wv^*\|^2] - \frac{1}{2\eta_t}  \E[\|\wv^{t+1} - \wv^*\|^2]
\end{align*}
\end{frame}

\begin{frame}{Convergence Theorem}
\begin{theorem}
\label{theorem:basicSGD}
 Suppose $f$ is a $\lambda$-strongly convex function. If we choose the stepsize $\eta_t = \frac{1}{\lambda t }$, then after $T$ iterations of NonUnifSGD (Algorithm \ref{alg:SGD}) starting with $\wv^{1}=\bm{0}$, it holds that
    \[
        \E\big[ f\!\left(\frac1T\sum_{t=1}^T \wv^{t} \right) \big] - f(\wv^*) \le \frac{1}{2\lambda T}\sum_{t=1}^T \frac{\E[\|\gv_{i_t}^t\|^2]}{t}
    \]
    where $\gv_{i_t}^t=\frac{\chiv_{i_t}^t(\wv^{t})}{np_{i_t}}$ and the expectation is taken with respect to the distribution $\p$.
\end{theorem}
\end{frame}

\begin{frame}{Proof Snapshot}
\begin{figure}[H]
        \includegraphics[width = 0.8\textwidth]{images/snapshot.png} 
    \label{fig:two_updates}
\end{figure}
\end{frame}

\begin{frame}{Two corollaries}
\begin{definition}\label{def:WG}
Define $G := \max_{i, t}\{ \|\chiv_{i}^t(\wv^{t})\|^2\}$ ($i = 1\dots n$, $t=1\dots T$).
Define $W := \max_{i,t}\{\E[\|\chiv_{i}^t(\wv^{t})\|^2]\}$ ($i = 1\dots n$, $t=1\dots T$).
\end{definition}
\begin{corollary}\label{corollary:maxsubgrad}
Assume that $\max_{t}\{\|\chiv_{i_t}^t(\wv^t)\|^2\} \le G$ for all $t$. $\E[\|\chiv_{i_t}^t(\wv^t)\|^2] \le W$ for all $t$ and $p_i > \epsilon$ for all $i=\{1\dots, n\}$,
    \begin{align*}
        \E\big[f\!\left(\frac1T\sum_{t=1}^T \wv^{t} \right)\big]- f(\wv^*) \le \frac{1}{2\lambda T} \sum_{t=1}^T \frac{G}{\epsilon nt}
\le \frac{G(\ln T+1)}{2\lambda \epsilon nT}\\
        \E\big[f\!\left(\frac1T\sum_{t=1}^T \wv^{t} \right)\big]- f(\wv^*)  \le \frac{1}{2\lambda T}\sum_{t=1}^T \frac{W}{n^2\epsilon^2 t}
\le \frac{W(\ln T+1)}{2\lambda Tn^2\epsilon^2}
    \end{align*}
\end{corollary}
\end{frame}

\begin{frame}{NonUnifSDCA}
\begin{algorithm}[H]
    \label{alg:SDCA}
    \caption{Non-Uniform Stochastic Dual Coordinate Ascent}
    \SetKwInput{Init}{Initialize}
    \SetKwFor{Forloop}{for}{}{end}
    \SetAlgoLined
    \KwIn{$\lambda > 0$, $p_i = \frac{\|\xv_i\|}{\sum_{j=1}^n \|\xv_j\|}$, $\forall i\in \{1,\ldots,n\}$.
    }
    \KwData{$\{(\xv_i,y_i)\}_{i=1}^n$}
    \Init{
        $\alphav^1 = \bm{0}$, $\wv^{1}= \bm{0}$.    }
    \Forloop{ $t = 1,2, \dots ,T$}{
        Sample $i_t$ from $\{1,\ldots,n\}$ based on $\p$; \\
        Calculate $\Delta \alpha_{i_t}^{t} = \argmax_{\Delta \alpha_{i_t}^t}[-\frac{\lambda n}{2}\|\wv^{t}+\frac{1}{\lambda n}\Delta \alpha_{i_t}^t \xv_{i_t} \|^2-\ell_{i_t}^*(-(\alpha_{i_t}^{t}+\Delta\alpha_{i_{t}}^t))]$; \\ 
        Set $\alpha_{i_{t}}^{t+1}\leftarrow \alpha_{i_{t}}^{t}+\Delta\alpha_{i_t}^{t}$;\\
        Set $\wv^{t+1}\leftarrow \wv^{t}+\frac{1}{\lambda n}\Delta\alpha_{i_t}^{t}\xv_{i_t} $;\\
    }
        \KwOut{$\wv^{T+1}$}
\end{algorithm}
\end{frame}
